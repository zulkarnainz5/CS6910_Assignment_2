# -*- coding: utf-8 -*-
"""Assignment_DL_2A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/assignment-dl-2a-ipynb-cd537a17-44a5-4133-b301-087513b3519a.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240416/auto/storage/goog4_request%26X-Goog-Date%3D20240416T033410Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D372f084b887a20226191336fc10c6f8812ae6f3bd84e3ca7ab269fb674bd95a463933d8d4132604b4ff6cf86e23d50c01318c0af86cc7f968abf1309dbea4a4e4117c6752a522971935e18f6b43aa86c0353480c14c8601e2f2e59c0342ff2c8e8757f4356b85b3ec29469e777d39cbeb163fe9a62b9da11ad68382628a44e1a898ae1d5d43a2493d43f945be982c55c219f3d82803248c91f0f9e3d9617a5fe37ed06564f8f1eab7522af8b740df8e09a3e4a7fad9c770e513ae5d6cfaa58ba7dac8b39ac442d6735e93919ba1d6e695f677aa6501ff0f32c9067d909e22f19f42fa9cb768995f789168423770c95a20aebd64930f92db197f5f447064bb374
"""

import numpy as np
import torch
import torchvision
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import ImageFolder
import torch.nn.init
import torch.optim as optim
from torch.autograd import Variable
from torch.nn.functional import batch_norm
import matplotlib.pyplot as plt
from tqdm import tqdm
import zipfile
import os

!pip install wandb
import wandb

!wandb login

entity_name="team_zulkar"

project_name="CS6910_Assignment_2A"

"""## **Data Preparation**"""

def unaug_data():
    data = '/kaggle/input/inaturalist-dataset/inaturalist_12K'

    ## Unaugmented data


    data_transforms = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    #train dataset
    train_dataset = datasets.ImageFolder(root=f"{data}/train", transform=data_transforms)
    #test dataset
    test_dataset = datasets.ImageFolder(root=f"{data}/val", transform=data_transforms)

    initial_size = len(train_dataset)
    train_size = int(0.8 * initial_size)
    val_size = initial_size - train_size

    # Spliting the train dataset into train and validation data
    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])

    # Loading the dataset
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)

    return  train_loader, test_loader, val_loader

def aug_data():
    data = '/kaggle/input/inaturalist-dataset/inaturalist_12K'

    ## augmented data


    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),
              transforms.RandomVerticalFlip(p=0.5),
              transforms.RandomRotation((120)),
              transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter()]), p=0.5),
              transforms.Resize((224,224)),
              transforms.ToTensor(),
              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    test_transform = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])


    #train dataset
    train_dataset = datasets.ImageFolder(root=f"{data}/train", transform=train_transform)
    #test dataset
    test_dataset = datasets.ImageFolder(root=f"{data}/val", transform=test_transform)

    initial_size = len(train_dataset)
    train_size = int(0.8 * initial_size)
    val_size = initial_size - train_size

    # Spliting the train dataset into train and validation data
    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])

    # Loading the dataset
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)
    return  train_loader, test_loader, val_loader

train_loader_au, test_loader_au, val_loader_au = aug_data()
train_loader_un, test_loader_un, val_loader_un = unaug_data()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

def imshow(img):
    img = img / 2 + 0.5  # Unnormalize
    plt.imshow(np.transpose(img, (1, 2, 0)))  # Convert from Tensor to image

# Display a batch of images
dataiter = iter(train_loader_un)
images, labels = next(dataiter)
images = images.numpy()  # Convert images to numpy for display

fig = plt.figure(figsize=(25, 4))
for i in np.arange(20):
    ax = fig.add_subplot(2, 20 // 2, i + 1, xticks=[], yticks=[])
    imshow(images[i])

"""## **Question-1**"""

##Formula to calculate output size: [(Wâˆ’K+2P)/S]+1
def out_dimension(input,filter,stride,padding):
  out_dim=(input-filter+2*padding)//stride + 1
  return out_dim

class CNN_model(nn.Module):
  def __init__(self, no_of_filters, filters_size, act_func, neurons_dense_layer, input=224,   dropout=0.1, batch_norm=False):

        if act_func=="relu":
          act_func=nn.functional.relu
        elif act_func=='elu':
          act_func=nn.functional.elu
        elif act_func=='leaky_relu':
          act_func=nn.functional.leaky_relu



        super(CNN_model,self).__init__()
        self.batch_norm=batch_norm
        self.act_func=act_func
        self.neurons_dense_layer=neurons_dense_layer



        self.conv1 = nn.Conv2d(3, no_of_filters[0], filters_size[0], stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(no_of_filters[0])
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)
        width_conv=out_dimension(224,filters_size[0],1,1)
        width_mp=out_dimension(width_conv,2,2,0)

        for i in range(1,5):
          setattr(self, f"conv{i+1}", nn.Conv2d(no_of_filters[i-1], no_of_filters[i], filters_size[i], stride=1, padding=1))
          setattr(self, f"bn{i+1}", nn.BatchNorm2d(no_of_filters[i]))
          setattr(self, f"maxpool{i+1}", nn.MaxPool2d(kernel_size=2))
          width_conv=out_dimension(width_mp,filters_size[i],1,1)
          width_mp=out_dimension(width_conv,2,2,0)

        width_out=width_mp*width_mp*no_of_filters[-1]
        self.width_out=width_out

        self.dropout=nn.Dropout(dropout)
        self.Flatten=nn.Flatten(start_dim=1,end_dim=-1)
        self.dense_layer = nn.Linear(width_out, neurons_dense_layer)
        self.output_layer = nn.Linear(neurons_dense_layer, 10)

        print(width_out)


  def forward(self, x):
        x = self.conv1(x)
        if self.batch_norm==True:
          x = self.bn1(x)
        x = self.act_func(x)
        x = self.maxpool1(x)

        for i in range(1,4):
          x = getattr(self, f"conv{i+1}")(x)
          if self.batch_norm:
              x = getattr(self, f"bn{i+1}")(x)
          x = self.act_func(x)
          x = getattr(self, f"maxpool{i+1}")(x)
          x = self.dropout(x)


        x = self.conv5(x)
        if self.batch_norm==True:
          x = self.bn5(x)
        x = self.act_func(x)
        x = self.maxpool5(x)

        x = x.view(-1,self.width_out)
        x = self.dense_layer(x)
        x = self.act_func(x)
        x = self.dropout(x)

        x = self.output_layer(x)
        return x

no_of_filters = [6,6,6,16,16]
filters_size = [3,3,3,3,3]
act_func = 'relu'
neurons_dense_layer = 120

print(torch.cuda.is_available())
CNN_model(no_of_filters, filters_size, act_func, neurons_dense_layer)

My_model = CNN_model(no_of_filters, filters_size, act_func, neurons_dense_layer)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(My_model.parameters(), lr=0.001)

# Train the model (customize this part based on your training loop)
num_epochs = 3
for epoch in tqdm(range(num_epochs)):
    for batch in train_loader_un:
        inputs, labels = batch
        optimizer.zero_grad()
        outputs = My_model(inputs)
        print(labels.shape, inputs.shape, outputs.shape)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f"epoch{epoch} - Loss: {loss.item():.4f}")

"""## **Question-2**"""

def train():

    config_defaults = {
      'batch_norm': False,
      'no_of_filters': [32,32,64,64,128],
      'dropout': 0.2,
      'data_augmentation': True,
      'num_epochs' : 10,
      'batch_size': 64,
      'neurons_dense_layer': 64,
      'learning_rate': 0.001,
      'act_func': "relu",
      'optimizer': "Adam",
      'filters_size': [3,3,3,3,3]

    }
      # Initializing the wandb run
    wandb.init(config=config_defaults)
    config = wandb.config
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = CNN_model(config.no_of_filters,config.filters_size,act_func,config.neurons_dense_layer, config.dropout,config.batch_norm).to(device)
    # Data loading

    if config.data_augmentation:
        train_loader, test_loader, val_loader = aug_data()
    else:
        train_loader, test_loader, val_loader = unaug_data()

    name_run = str(config.batch_norm) + "_"  + str(config.dropout) +  "_" + str(config.neurons_dense_layer) + \
                "_" + str(config.data_augmentation) + "_" + str(config.num_epochs)

    wandb.run.name = name_run
    wandb_log = True

    optimizer = optim.Adam(model.parameters(),lr=config.learning_rate)
    criterion = nn.CrossEntropyLoss().to(device)
    gpu_train = torch.cuda.is_available()

    for epoch in tqdm(range(config.num_epochs)):

        train_loss = 0.0
        val_loss = 0.0
        val_accuracy = 0.0
        total=0.0
        correct=0.0


        model.train()
        for batch in train_loader:
            inputs, labels = batch
            if gpu_train:
              inputs, labels = inputs.cuda(), labels.cuda()
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()*inputs.size(0)

        model.eval()
        for batch in val_loader:
            inputs, labels = batch
            if gpu_train:
              inputs, labels = inputs.cuda(), labels.cuda()
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()*inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        val_accuracy = 100 * correct / total

    train_loss = train_loss/len(train_loader.dataset)
    val_loss = val_loss/len(val_loader.dataset)
    val_accuracy = val_accuracy
    if(wandb_log==True):
       epoc=0

       log_dict = {"Train_loss": train_loss, "Validation_loss": val_loss, "Validation_Accuracy": val_accuracy}
       epoc=epoc+1
       print('Epoch: {} \tTraining Loss: {:.4f} \tValidation Loss: {:.5f} \tValidation Accuracy: {:.4f}'.format(epoc,
        train_loss, val_loss,val_accuracy))
       wandb.log(log_dict)

    wandb.run.save()
    wandb.run.finish()
    return model

# Setting up the entity name and project name.
entity_name = "team_zulkar"
project_name = "CS6910_Assignment_2A"

def sweeper(entity_name, project_name):

    hyperparameters={

    'batch_norm': {
        'values':[True, False]
    },
    'no_of_filters':{
        'values': [[32,32,32,32,32],[128,64,64,32,32],[64,64,64,64,64]]

    },

    'dropout':{
        'values':[0.0, 0.5, 0.6, 0.4]
    },

    'data_augmentation':{
        'values':[True, False]
    },

    'num_epochs': {
        'values':[10, 15, 20]
    },

    'batch_size': {
        'values':[32, 64, 128]
    },

    'neurons_dense_layer': {
        'values':[32, 64, 128, 256]
    },

    'learning_rate': {
        'values':[0.001, 0.0001]
    },

    'activation': {
            'values': ['relu','elu','leaky_relu']
    },

    'filters_size': {
        'values': [[3,3,5,7,7], [5,5,5,5,5], [3,3,3,3,3]]
    }

    }

    # Using bayes method for hyperparameter sweeps to curb the unnecessary configurations
    sweep_config = {
      'method' : 'bayes',
      'metric' :{
          'name': 'val_acc',
          'goal': 'maximize'
      },
      'parameters': hyperparameters
    }

    sweep_id = wandb.sweep(sweep_config, entity=entity_name, project=project_name)
    wandb.agent(sweep_id, train)

sweeper(entity_name, project_name)

sweeper(entity_name, project_name)

"""## **Question-3**

1. Using high number of neurons in dense layer is better.
2. Using more no. of filters in initial layers is better.
3. Data augmentation is many times good.
4. Using small filters in initial layers is better.

## **Question-4**

**From above hypermeters tuning i found best hypermeters with validation accuracy of 35.1%,so i have run the model with test data on these best hypermeters below**
"""

# Function to run the model on the best hyperparameters
def test_data_training(entity_name, project_name):

    best_hyperparameters = {
      'batch_norm': False,
      'no_of_filters': [64, 64, 64, 64, 64],
      'dropout': 0.6,
      'data_augmentation': True,
      'num_epochs' : 20,
      'batch_size': 32,
      'neurons_dense_layer': 256,
      'learning_rate': 0.001,
      'act_func': "relu",
      'optimizer': "Adam",
      'filters_size': [3, 3, 3, 3, 3]
    }

     # Initializing the wandb run
    wandb.init(config=best_hyperparameters)
    config = wandb.config
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = CNN_model(config.no_of_filters,config.filters_size,act_func,config.neurons_dense_layer, config.dropout,config.batch_norm).to(device)
    # Data loading

    if config.data_augmentation:
        train_loader, test_loader, val_loader = aug_data()
    else:
        train_loader, test_loader, val_loader = unaug_data()

    name_run = "Test Run"

    wandb.run.name = name_run
    wandb_log = True

    optimizer = optim.Adam(model.parameters(),lr=config.learning_rate)
    criterion = nn.CrossEntropyLoss().to(device)
    gpu_train = torch.cuda.is_available()

    for epoch in tqdm(range(config.num_epochs)):

        test_loss = 0.0
        test_accuracy = 0.0
        total = 0
        correct = 0

        model.train()
        for batch in test_loader:
            inputs, labels = batch
            if gpu_train:
              inputs, labels = inputs.cuda(), labels.cuda()
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            test_loss += loss.item()*inputs.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        test_accuracy = 100 * correct / total
        print(f"Test Accuracy: {test_accuracy:.2f}%")

    test_loss = test_loss/len(test_loader.dataset)
    test_accuracy = test_accuracy

    if(wandb_log==True):
       epoc=0
       log_dict = {"Test_loss": test_loss, "Test_Accuracy": test_accuracy}
       epoc=epoc+1
       print('Epoch: {} \tTest Loss: {:.4f} \tTest Accuracy: {:.4f}'.format(epoc,
        test_loss,test_accuracy))
       wandb.log(log_dict)

    wandb.run.save()
    wandb.run.finish()
    return model

model = test_data_training(entity_name, project_name)

"""**So, with these best hyperparameters the test accuracy comes out to be 95.5%**

I dont know why the accuracy comes this much good on test data, maybe because before running this best hypermeters sweep on this untouched test data, a previous sweep of hyperparameters tuning which was aborted and not completed, continued on this test data.
"""

